/*
  NOTE: The Env type, and all Cloudflare Workers types, are ambient. They are auto-generated by wrangler. They never need to be imported.
*/

/**
 * Expected structure for a single asset storage task.
 * Sent by Convex to the /enqueue endpoint and put into the queue.
 */
interface AssetStorageTask {
  sourceUrl: string
  storageKey: string
}

/**
 * Expected payload structure from Convex to the /enqueue endpoint.
 */
interface EnqueueBatchPayload {
  tasks: AssetStorageTask[]
}

const BASE_RETRY_DELAY_SECONDS = 5 // Initial delay for backoff
const MAX_RETRY_DELAY_SECONDS = 300 // Max delay (5 minutes)

/**
 * Calculates exponential backoff delay.
 * @param attempts Number of delivery attempts (from message.attempts)
 * @param baseDelaySeconds Initial delay in seconds
 * @returns Delay in seconds, capped at MAX_RETRY_DELAY_SECONDS
 */
function calculateExponentialBackoff(attempts: number, baseDelaySeconds: number): number {
  // Formula: base * 2^(attempts - 1), but ensure it starts reasonable
  const delay = baseDelaySeconds * (2 ** Math.max(0, attempts - 1))
  return Math.min(delay, MAX_RETRY_DELAY_SECONDS)
}

export default {
  /**
   * Handles incoming HTTP requests from Convex to enqueue a *batch* of tasks.
   */
  async fetch(request: Request, env: Env): Promise<Response> {
    if (request.method !== 'POST') {
      return new Response('Method Not Allowed', { status: 405 })
    }
    const url = new URL(request.url)
    if (url.pathname !== '/enqueue') {
      return new Response('Not Found', { status: 404 })
    }

    // --- Authentication (Simplified) ---
    const authHeader = request.headers.get('Authorization') || ''
    const providedToken = authHeader.startsWith('Bearer ') ? authHeader.substring(7) : null

    if (!env.ASSETS_SECRET) {
      console.error('ASSETS_SECRET is not set in Worker environment.')
      return new Response('Internal Server Error: Worker configuration missing', { status: 500 })
    }
    // Simple string comparison (timing attacks not a concern here)
    if (providedToken !== env.ASSETS_SECRET) {
      console.warn('Unauthorized attempt to enqueue tasks.')
      return new Response('Unauthorized: Invalid token', { status: 401 })
    }

    // --- Payload Validation and Batch Enqueue ---
    let payload: EnqueueBatchPayload
    try {
      payload = await request.json()
      if (!payload || !Array.isArray(payload.tasks) || payload.tasks.length === 0) {
        throw new Error('Invalid payload: Missing or empty \'tasks\' array.')
      }
      // Optional: Add deeper validation for each task in the array
      for (const task of payload.tasks) {
        if (!task.sourceUrl || !task.storageKey) {
          throw new Error(`Invalid task in batch: Missing sourceUrl or storageKey. Task: ${JSON.stringify(task)}`)
        }
      }
    }
    catch (e: any) {
      console.error('Failed to parse or validate request body:', e.message)
      return new Response(`Bad Request: ${e.message}`, { status: 400 })
    }

    try {
      // Enqueue each task individually
      const sendPromises = payload.tasks.map(task => env.QUEUE.send(task)) // QUEUE binding sends AssetStorageTask
      const results = await Promise.allSettled(sendPromises)

      const failedSends = results.filter(r => r.status === 'rejected')
      if (failedSends.length > 0) {
        console.error(`Failed to send ${failedSends.length} out of ${payload.tasks.length} messages to the queue.`, failedSends)
        // Return partial success or failure? For now, report overall failure if any send fails.
        return new Response('Internal Server Error: Failed to enqueue some tasks', { status: 500 })
      }

      console.log(`Successfully enqueued batch of ${payload.tasks.length} tasks.`)
      return new Response(JSON.stringify({ success: true, enqueuedCount: payload.tasks.length }), {
        headers: { 'Content-Type': 'application/json' },
      })
    }
    catch (e: any) {
      console.error(`Fatal error during batch send to queue: ${e}`)
      return new Response('Internal Server Error: Failed to enqueue batch', { status: 500 })
    }
  },

  /**
   * Handles messages consumed from the Queue.
   */
  async queue(
    batch: MessageBatch<unknown>,
    env: Env,
  ): Promise<void> {
    console.log(`Processing batch of ${batch.messages.length} messages from queue ${batch.queue}`)
    const typedBatch = batch as MessageBatch<AssetStorageTask> // Updated interface name

    const promises = typedBatch.messages.map(async (message) => {
      const task = message.body
      console.log(`Processing task for storageKey: ${task.storageKey}`) // Log uses storageKey

      try {
        // 0. Check if object already exists in R2
        const existingObject = await env.BUCKET.head(task.storageKey)
        if (existingObject) {
          // Object exists, skip processing and acknowledge
          console.log(`Object already exists for key ${task.storageKey}, skipping upload.`)
          message.ack()
          return // Stop processing this message
        }
        // If head throws/returns null, object doesn't exist (expected case)

        // 1. Fetch the asset from the source URL
        console.log(`Fetching ${task.sourceUrl}...`)
        const assetResponse = await fetch(task.sourceUrl, { headers: { 'User-Agent': 'CivitaiCrawler/1.0' } })
        if (!assetResponse.ok) {
          throw new Error(
            `Failed to fetch asset from ${task.sourceUrl}: ${assetResponse.status} ${assetResponse.statusText}`,
          )
        }
        if (!assetResponse.body) {
          throw new Error(`Fetch response from ${task.sourceUrl} has no body`)
        }

        // 2. Store the asset in R2 using streaming upload
        console.log(`Storing ${task.storageKey} in R2...`)
        const r2Object = await env.BUCKET.put(task.storageKey, assetResponse.body, {
          httpMetadata: assetResponse.headers,
        })

        if (!r2Object || !r2Object.key) {
          throw new Error(`Failed to put object to R2 for key ${task.storageKey}. R2 put returned null or missing key.`)
        }

        console.log(`Successfully stored ${r2Object.key} (Size: ${r2Object.size}) in R2.`)

        // 3. Acknowledge the message - Success!
        message.ack()
        console.log(`Acknowledged message for key ${task.storageKey}`) // Log uses storageKey
      }
      catch (error: any) {
        // Handle R2 head errors specifically if needed (e.g., permissions vs not found)
        if (error.message.includes('The specified key does not exist')) {
          // This is expected if the object wasn't found by head(), log and proceed if necessary
          // but the main try block should handle the fetch/put errors
          console.debug(`R2 head check confirmed key ${task.storageKey} does not exist, proceeding to fetch/put.`)
        }

        console.error(
          `FAILED processing storage task for key ${task.storageKey}:`,
          error.message,
        )

        // Retry with exponential backoff
        const delaySeconds = calculateExponentialBackoff(message.attempts, BASE_RETRY_DELAY_SECONDS)
        message.retry({ delaySeconds })
        console.log(`Retrying message for key ${task.storageKey} with delay ${delaySeconds}s (Attempt ${message.attempts + 1})`)
      }
    })

    await Promise.allSettled(promises)
    console.log(`Finished processing batch from queue ${batch.queue}`)
  },
}
